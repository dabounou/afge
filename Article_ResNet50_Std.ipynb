{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d4c46e-f2b8-4d5d-aa6b-28943d23ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpro/opt/anaconda3/envs/Torch_Info_theory/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/vpro/opt/anaconda3/envs/Torch_Info_theory/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/2239 (0%)]\tLoss: 2.431898\n",
      "Train Epoch: 1 [320/2239 (14%)]\tLoss: 2.264305\n",
      "Train Epoch: 1 [640/2239 (29%)]\tLoss: 1.809639\n",
      "Train Epoch: 1 [960/2239 (43%)]\tLoss: 2.062043\n",
      "Train Epoch: 1 [1280/2239 (57%)]\tLoss: 1.383193\n",
      "Train Epoch: 1 [1600/2239 (71%)]\tLoss: 1.765794\n",
      "Train Epoch: 1 [1920/2239 (86%)]\tLoss: 1.232962\n",
      "Epoch 1 training time: 976.82 seconds\n",
      "\n",
      "Test set: Average loss: 1.8091, Accuracy: 45/118 (38.14%)\n",
      "\n",
      "Train Epoch: 2 [0/2239 (0%)]\tLoss: 1.309400\n",
      "Train Epoch: 2 [320/2239 (14%)]\tLoss: 1.492102\n",
      "Train Epoch: 2 [640/2239 (29%)]\tLoss: 1.388095\n",
      "Train Epoch: 2 [960/2239 (43%)]\tLoss: 1.775414\n",
      "Train Epoch: 2 [1280/2239 (57%)]\tLoss: 1.414167\n",
      "Train Epoch: 2 [1600/2239 (71%)]\tLoss: 1.309518\n",
      "Train Epoch: 2 [1920/2239 (86%)]\tLoss: 2.113006\n",
      "Epoch 2 training time: 849.61 seconds\n",
      "\n",
      "Test set: Average loss: 2.0114, Accuracy: 47/118 (39.83%)\n",
      "\n",
      "Train Epoch: 3 [0/2239 (0%)]\tLoss: 1.140125\n",
      "Train Epoch: 3 [320/2239 (14%)]\tLoss: 1.658458\n",
      "Train Epoch: 3 [640/2239 (29%)]\tLoss: 1.239432\n",
      "Train Epoch: 3 [960/2239 (43%)]\tLoss: 1.174221\n",
      "Train Epoch: 3 [1280/2239 (57%)]\tLoss: 1.445855\n",
      "Train Epoch: 3 [1600/2239 (71%)]\tLoss: 1.500790\n",
      "Train Epoch: 3 [1920/2239 (86%)]\tLoss: 1.087230\n",
      "Epoch 3 training time: 813.29 seconds\n",
      "\n",
      "Test set: Average loss: 2.7975, Accuracy: 32/118 (27.12%)\n",
      "\n",
      "Train Epoch: 4 [0/2239 (0%)]\tLoss: 1.108769\n",
      "Train Epoch: 4 [320/2239 (14%)]\tLoss: 1.014430\n",
      "Train Epoch: 4 [640/2239 (29%)]\tLoss: 1.462603\n",
      "Train Epoch: 4 [960/2239 (43%)]\tLoss: 0.916363\n",
      "Train Epoch: 4 [1280/2239 (57%)]\tLoss: 1.405799\n",
      "Train Epoch: 4 [1600/2239 (71%)]\tLoss: 1.425296\n",
      "Train Epoch: 4 [1920/2239 (86%)]\tLoss: 1.101508\n",
      "Epoch 4 training time: 988.65 seconds\n",
      "\n",
      "Test set: Average loss: 1.8852, Accuracy: 54/118 (45.76%)\n",
      "\n",
      "Train Epoch: 5 [0/2239 (0%)]\tLoss: 1.211561\n",
      "Train Epoch: 5 [320/2239 (14%)]\tLoss: 0.908444\n",
      "Train Epoch: 5 [640/2239 (29%)]\tLoss: 0.971837\n",
      "Train Epoch: 5 [960/2239 (43%)]\tLoss: 0.927109\n",
      "Train Epoch: 5 [1280/2239 (57%)]\tLoss: 1.068641\n",
      "Train Epoch: 5 [1600/2239 (71%)]\tLoss: 1.049437\n",
      "Train Epoch: 5 [1920/2239 (86%)]\tLoss: 0.989978\n",
      "Epoch 5 training time: 1071.99 seconds\n",
      "\n",
      "Test set: Average loss: 1.9483, Accuracy: 40/118 (33.90%)\n",
      "\n",
      "Train Epoch: 6 [0/2239 (0%)]\tLoss: 1.300521\n",
      "Train Epoch: 6 [320/2239 (14%)]\tLoss: 1.294235\n",
      "Train Epoch: 6 [640/2239 (29%)]\tLoss: 0.992438\n",
      "Train Epoch: 6 [960/2239 (43%)]\tLoss: 1.438649\n",
      "Train Epoch: 6 [1280/2239 (57%)]\tLoss: 1.208487\n",
      "Train Epoch: 6 [1600/2239 (71%)]\tLoss: 1.312853\n",
      "Train Epoch: 6 [1920/2239 (86%)]\tLoss: 1.107697\n",
      "Epoch 6 training time: 1303.45 seconds\n",
      "\n",
      "Test set: Average loss: 2.6007, Accuracy: 37/118 (31.36%)\n",
      "\n",
      "Train Epoch: 7 [0/2239 (0%)]\tLoss: 0.648348\n",
      "Train Epoch: 7 [320/2239 (14%)]\tLoss: 1.120298\n",
      "Train Epoch: 7 [640/2239 (29%)]\tLoss: 1.798549\n",
      "Train Epoch: 7 [960/2239 (43%)]\tLoss: 1.412499\n",
      "Train Epoch: 7 [1280/2239 (57%)]\tLoss: 1.206744\n",
      "Train Epoch: 7 [1600/2239 (71%)]\tLoss: 0.797903\n",
      "Train Epoch: 7 [1920/2239 (86%)]\tLoss: 1.061711\n",
      "Epoch 7 training time: 1274.11 seconds\n",
      "\n",
      "Test set: Average loss: 1.7331, Accuracy: 52/118 (44.07%)\n",
      "\n",
      "Train Epoch: 8 [0/2239 (0%)]\tLoss: 1.077165\n",
      "Train Epoch: 8 [320/2239 (14%)]\tLoss: 1.131939\n",
      "Train Epoch: 8 [640/2239 (29%)]\tLoss: 0.923515\n",
      "Train Epoch: 8 [960/2239 (43%)]\tLoss: 1.237925\n",
      "Train Epoch: 8 [1280/2239 (57%)]\tLoss: 0.922194\n",
      "Train Epoch: 8 [1600/2239 (71%)]\tLoss: 1.100235\n",
      "Train Epoch: 8 [1920/2239 (86%)]\tLoss: 0.772303\n",
      "Epoch 8 training time: 1458.01 seconds\n",
      "\n",
      "Test set: Average loss: 2.0309, Accuracy: 53/118 (44.92%)\n",
      "\n",
      "Train Epoch: 9 [0/2239 (0%)]\tLoss: 0.776254\n",
      "Train Epoch: 9 [320/2239 (14%)]\tLoss: 0.938876\n",
      "Train Epoch: 9 [640/2239 (29%)]\tLoss: 0.994139\n",
      "Train Epoch: 9 [960/2239 (43%)]\tLoss: 0.973213\n",
      "Train Epoch: 9 [1280/2239 (57%)]\tLoss: 1.266005\n",
      "Train Epoch: 9 [1600/2239 (71%)]\tLoss: 1.238292\n",
      "Train Epoch: 9 [1920/2239 (86%)]\tLoss: 0.810518\n",
      "Epoch 9 training time: 1469.49 seconds\n",
      "\n",
      "Test set: Average loss: 2.6271, Accuracy: 42/118 (35.59%)\n",
      "\n",
      "Train Epoch: 10 [0/2239 (0%)]\tLoss: 1.517972\n",
      "Train Epoch: 10 [320/2239 (14%)]\tLoss: 0.662073\n",
      "Train Epoch: 10 [640/2239 (29%)]\tLoss: 1.386409\n",
      "Train Epoch: 10 [960/2239 (43%)]\tLoss: 0.926024\n",
      "Train Epoch: 10 [1280/2239 (57%)]\tLoss: 1.040813\n",
      "Train Epoch: 10 [1600/2239 (71%)]\tLoss: 1.083254\n",
      "Train Epoch: 10 [1920/2239 (86%)]\tLoss: 0.721976\n",
      "Epoch 10 training time: 1490.46 seconds\n",
      "\n",
      "Test set: Average loss: 2.6311, Accuracy: 49/118 (41.53%)\n",
      "\n",
      "Train Epoch: 11 [0/2239 (0%)]\tLoss: 0.917766\n",
      "Train Epoch: 11 [320/2239 (14%)]\tLoss: 0.894874\n",
      "Train Epoch: 11 [640/2239 (29%)]\tLoss: 1.022754\n",
      "Train Epoch: 11 [960/2239 (43%)]\tLoss: 1.180664\n",
      "Train Epoch: 11 [1280/2239 (57%)]\tLoss: 0.902937\n",
      "Train Epoch: 11 [1600/2239 (71%)]\tLoss: 0.788478\n",
      "Train Epoch: 11 [1920/2239 (86%)]\tLoss: 0.993344\n",
      "Epoch 11 training time: 1474.95 seconds\n",
      "\n",
      "Test set: Average loss: 2.0207, Accuracy: 54/118 (45.76%)\n",
      "\n",
      "Train Epoch: 12 [0/2239 (0%)]\tLoss: 1.108042\n",
      "Train Epoch: 12 [320/2239 (14%)]\tLoss: 0.753466\n",
      "Train Epoch: 12 [640/2239 (29%)]\tLoss: 1.037948\n",
      "Train Epoch: 12 [960/2239 (43%)]\tLoss: 0.956251\n",
      "Train Epoch: 12 [1280/2239 (57%)]\tLoss: 1.291853\n",
      "Train Epoch: 12 [1600/2239 (71%)]\tLoss: 0.818225\n",
      "Train Epoch: 12 [1920/2239 (86%)]\tLoss: 1.185880\n",
      "Epoch 12 training time: 1485.86 seconds\n",
      "\n",
      "Test set: Average loss: 2.4409, Accuracy: 46/118 (38.98%)\n",
      "\n",
      "Train Epoch: 13 [0/2239 (0%)]\tLoss: 1.278704\n",
      "Train Epoch: 13 [320/2239 (14%)]\tLoss: 1.168427\n",
      "Train Epoch: 13 [640/2239 (29%)]\tLoss: 1.097550\n",
      "Train Epoch: 13 [960/2239 (43%)]\tLoss: 0.545926\n",
      "Train Epoch: 13 [1280/2239 (57%)]\tLoss: 0.720917\n",
      "Train Epoch: 13 [1600/2239 (71%)]\tLoss: 0.775821\n",
      "Train Epoch: 13 [1920/2239 (86%)]\tLoss: 0.851738\n",
      "Epoch 13 training time: 1256.20 seconds\n",
      "\n",
      "Test set: Average loss: 2.0144, Accuracy: 48/118 (40.68%)\n",
      "\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Train Epoch: 14 [0/2239 (0%)]\tLoss: 0.693625\n",
      "Train Epoch: 14 [320/2239 (14%)]\tLoss: 0.834320\n",
      "Train Epoch: 14 [640/2239 (29%)]\tLoss: 0.754106\n",
      "Train Epoch: 14 [960/2239 (43%)]\tLoss: 0.896623\n",
      "Train Epoch: 14 [1280/2239 (57%)]\tLoss: 0.790547\n",
      "Train Epoch: 14 [1600/2239 (71%)]\tLoss: 1.097567\n",
      "Train Epoch: 14 [1920/2239 (86%)]\tLoss: 0.859523\n",
      "Epoch 14 training time: 5509.31 seconds\n",
      "\n",
      "Test set: Average loss: 1.8072, Accuracy: 57/118 (48.31%)\n",
      "\n",
      "Train Epoch: 15 [0/2239 (0%)]\tLoss: 0.836395\n",
      "Train Epoch: 15 [320/2239 (14%)]\tLoss: 1.174782\n",
      "Train Epoch: 15 [640/2239 (29%)]\tLoss: 0.542626\n",
      "Train Epoch: 15 [960/2239 (43%)]\tLoss: 0.846505\n",
      "Train Epoch: 15 [1280/2239 (57%)]\tLoss: 0.906400\n",
      "Train Epoch: 15 [1600/2239 (71%)]\tLoss: 0.655139\n",
      "Train Epoch: 15 [1920/2239 (86%)]\tLoss: 0.681102\n",
      "Epoch 15 training time: 1266.72 seconds\n",
      "\n",
      "Test set: Average loss: 1.7360, Accuracy: 60/118 (50.85%)\n",
      "\n",
      "Train Epoch: 16 [0/2239 (0%)]\tLoss: 0.648957\n",
      "Train Epoch: 16 [320/2239 (14%)]\tLoss: 0.597654\n",
      "Train Epoch: 16 [640/2239 (29%)]\tLoss: 0.868280\n",
      "Train Epoch: 16 [960/2239 (43%)]\tLoss: 0.645047\n",
      "Train Epoch: 16 [1280/2239 (57%)]\tLoss: 0.788363\n",
      "Train Epoch: 16 [1600/2239 (71%)]\tLoss: 0.757610\n",
      "Train Epoch: 16 [1920/2239 (86%)]\tLoss: 0.867603\n",
      "Epoch 16 training time: 1278.97 seconds\n",
      "\n",
      "Test set: Average loss: 1.7002, Accuracy: 61/118 (51.69%)\n",
      "\n",
      "Train Epoch: 17 [0/2239 (0%)]\tLoss: 0.618169\n",
      "Train Epoch: 17 [320/2239 (14%)]\tLoss: 0.683062\n",
      "Train Epoch: 17 [640/2239 (29%)]\tLoss: 0.861204\n",
      "Train Epoch: 17 [960/2239 (43%)]\tLoss: 1.092650\n",
      "Train Epoch: 17 [1280/2239 (57%)]\tLoss: 0.521168\n",
      "Train Epoch: 17 [1600/2239 (71%)]\tLoss: 0.569078\n",
      "Train Epoch: 17 [1920/2239 (86%)]\tLoss: 0.912348\n",
      "Epoch 17 training time: 1285.82 seconds\n",
      "\n",
      "Test set: Average loss: 1.6052, Accuracy: 62/118 (52.54%)\n",
      "\n",
      "Train Epoch: 18 [0/2239 (0%)]\tLoss: 0.640388\n",
      "Train Epoch: 18 [320/2239 (14%)]\tLoss: 0.592493\n",
      "Train Epoch: 18 [640/2239 (29%)]\tLoss: 0.722484\n",
      "Train Epoch: 18 [960/2239 (43%)]\tLoss: 0.533668\n",
      "Train Epoch: 18 [1280/2239 (57%)]\tLoss: 0.953520\n",
      "Train Epoch: 18 [1600/2239 (71%)]\tLoss: 0.668146\n",
      "Train Epoch: 18 [1920/2239 (86%)]\tLoss: 0.700585\n",
      "Epoch 18 training time: 1285.62 seconds\n",
      "\n",
      "Test set: Average loss: 1.7286, Accuracy: 57/118 (48.31%)\n",
      "\n",
      "Train Epoch: 19 [0/2239 (0%)]\tLoss: 0.651298\n",
      "Train Epoch: 19 [320/2239 (14%)]\tLoss: 0.499424\n",
      "Train Epoch: 19 [640/2239 (29%)]\tLoss: 0.729631\n",
      "Train Epoch: 19 [960/2239 (43%)]\tLoss: 0.574347\n",
      "Train Epoch: 19 [1280/2239 (57%)]\tLoss: 0.619301\n",
      "Train Epoch: 19 [1600/2239 (71%)]\tLoss: 0.488945\n",
      "Train Epoch: 19 [1920/2239 (86%)]\tLoss: 0.688972\n",
      "Epoch 19 training time: 1300.00 seconds\n",
      "\n",
      "Test set: Average loss: 1.6450, Accuracy: 58/118 (49.15%)\n",
      "\n",
      "Train Epoch: 20 [0/2239 (0%)]\tLoss: 0.644405\n",
      "Train Epoch: 20 [320/2239 (14%)]\tLoss: 0.506574\n",
      "Train Epoch: 20 [640/2239 (29%)]\tLoss: 0.632299\n",
      "Train Epoch: 20 [960/2239 (43%)]\tLoss: 0.840509\n",
      "Train Epoch: 20 [1280/2239 (57%)]\tLoss: 0.750630\n",
      "Train Epoch: 20 [1600/2239 (71%)]\tLoss: 0.629389\n",
      "Train Epoch: 20 [1920/2239 (86%)]\tLoss: 0.743536\n",
      "Epoch 20 training time: 1293.78 seconds\n",
      "\n",
      "Test set: Average loss: 1.6293, Accuracy: 65/118 (55.08%)\n",
      "\n",
      "Train Epoch: 21 [0/2239 (0%)]\tLoss: 0.511763\n",
      "Train Epoch: 21 [320/2239 (14%)]\tLoss: 0.496395\n",
      "Train Epoch: 21 [640/2239 (29%)]\tLoss: 0.593318\n",
      "Train Epoch: 21 [960/2239 (43%)]\tLoss: 0.737846\n",
      "Train Epoch: 21 [1280/2239 (57%)]\tLoss: 0.536825\n",
      "Train Epoch: 21 [1600/2239 (71%)]\tLoss: 0.778684\n",
      "Train Epoch: 21 [1920/2239 (86%)]\tLoss: 0.493083\n",
      "Epoch 21 training time: 1310.45 seconds\n",
      "\n",
      "Test set: Average loss: 1.9616, Accuracy: 57/118 (48.31%)\n",
      "\n",
      "Train Epoch: 22 [0/2239 (0%)]\tLoss: 0.780972\n",
      "Train Epoch: 22 [320/2239 (14%)]\tLoss: 1.053055\n",
      "Train Epoch: 22 [640/2239 (29%)]\tLoss: 0.555214\n",
      "Train Epoch: 22 [960/2239 (43%)]\tLoss: 1.068213\n",
      "Train Epoch: 22 [1280/2239 (57%)]\tLoss: 0.696828\n",
      "Train Epoch: 22 [1600/2239 (71%)]\tLoss: 0.408237\n",
      "Train Epoch: 22 [1920/2239 (86%)]\tLoss: 0.580644\n",
      "Epoch 22 training time: 1316.26 seconds\n",
      "\n",
      "Test set: Average loss: 1.6901, Accuracy: 66/118 (55.93%)\n",
      "\n",
      "Train Epoch: 23 [0/2239 (0%)]\tLoss: 0.600463\n",
      "Train Epoch: 23 [320/2239 (14%)]\tLoss: 0.485748\n",
      "Train Epoch: 23 [640/2239 (29%)]\tLoss: 0.799378\n",
      "Train Epoch: 23 [960/2239 (43%)]\tLoss: 0.756898\n",
      "Train Epoch: 23 [1280/2239 (57%)]\tLoss: 0.598920\n",
      "Train Epoch: 23 [1600/2239 (71%)]\tLoss: 0.604082\n",
      "Train Epoch: 23 [1920/2239 (86%)]\tLoss: 0.607157\n",
      "Epoch 23 training time: 1551.71 seconds\n",
      "\n",
      "Test set: Average loss: 1.7625, Accuracy: 62/118 (52.54%)\n",
      "\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Train Epoch: 24 [0/2239 (0%)]\tLoss: 0.629817\n",
      "Train Epoch: 24 [320/2239 (14%)]\tLoss: 0.444986\n",
      "Train Epoch: 24 [640/2239 (29%)]\tLoss: 0.550205\n",
      "Train Epoch: 24 [960/2239 (43%)]\tLoss: 0.588930\n",
      "Train Epoch: 24 [1280/2239 (57%)]\tLoss: 0.418100\n",
      "Train Epoch: 24 [1600/2239 (71%)]\tLoss: 0.459663\n",
      "Train Epoch: 24 [1920/2239 (86%)]\tLoss: 0.580510\n",
      "Epoch 24 training time: 1329.51 seconds\n",
      "\n",
      "Test set: Average loss: 1.6873, Accuracy: 66/118 (55.93%)\n",
      "\n",
      "Train Epoch: 25 [0/2239 (0%)]\tLoss: 0.849790\n",
      "Train Epoch: 25 [320/2239 (14%)]\tLoss: 0.791261\n",
      "Train Epoch: 25 [640/2239 (29%)]\tLoss: 0.482118\n",
      "Train Epoch: 25 [960/2239 (43%)]\tLoss: 0.593343\n",
      "Train Epoch: 25 [1280/2239 (57%)]\tLoss: 0.720459\n",
      "Train Epoch: 25 [1600/2239 (71%)]\tLoss: 0.766855\n",
      "Train Epoch: 25 [1920/2239 (86%)]\tLoss: 0.369976\n",
      "Epoch 25 training time: 1302.71 seconds\n",
      "\n",
      "Test set: Average loss: 1.4721, Accuracy: 69/118 (58.47%)\n",
      "\n",
      "Train Epoch: 26 [0/2239 (0%)]\tLoss: 0.518547\n",
      "Train Epoch: 26 [320/2239 (14%)]\tLoss: 0.544902\n",
      "Train Epoch: 26 [640/2239 (29%)]\tLoss: 0.754439\n",
      "Train Epoch: 26 [960/2239 (43%)]\tLoss: 0.620063\n",
      "Train Epoch: 26 [1280/2239 (57%)]\tLoss: 0.699516\n",
      "Train Epoch: 26 [1600/2239 (71%)]\tLoss: 0.631088\n",
      "Train Epoch: 26 [1920/2239 (86%)]\tLoss: 1.153270\n",
      "Epoch 26 training time: 1317.12 seconds\n",
      "\n",
      "Test set: Average loss: 1.6338, Accuracy: 66/118 (55.93%)\n",
      "\n",
      "Train Epoch: 27 [0/2239 (0%)]\tLoss: 0.584542\n",
      "Train Epoch: 27 [320/2239 (14%)]\tLoss: 0.472337\n",
      "Train Epoch: 27 [640/2239 (29%)]\tLoss: 0.427424\n",
      "Train Epoch: 27 [960/2239 (43%)]\tLoss: 0.844104\n",
      "Train Epoch: 27 [1280/2239 (57%)]\tLoss: 0.792356\n",
      "Train Epoch: 27 [1600/2239 (71%)]\tLoss: 0.531195\n",
      "Train Epoch: 27 [1920/2239 (86%)]\tLoss: 0.588244\n",
      "Epoch 27 training time: 1375.02 seconds\n",
      "\n",
      "Test set: Average loss: 1.6905, Accuracy: 62/118 (52.54%)\n",
      "\n",
      "Train Epoch: 28 [0/2239 (0%)]\tLoss: 0.747788\n",
      "Train Epoch: 28 [320/2239 (14%)]\tLoss: 0.541141\n",
      "Train Epoch: 28 [640/2239 (29%)]\tLoss: 0.672848\n",
      "Train Epoch: 28 [960/2239 (43%)]\tLoss: 0.699669\n",
      "Train Epoch: 28 [1280/2239 (57%)]\tLoss: 0.636714\n",
      "Train Epoch: 28 [1600/2239 (71%)]\tLoss: 0.716129\n",
      "Train Epoch: 28 [1920/2239 (86%)]\tLoss: 0.565690\n",
      "Epoch 28 training time: 1459.29 seconds\n",
      "\n",
      "Test set: Average loss: 1.6443, Accuracy: 69/118 (58.47%)\n",
      "\n",
      "Train Epoch: 29 [0/2239 (0%)]\tLoss: 0.671733\n",
      "Train Epoch: 29 [320/2239 (14%)]\tLoss: 0.414892\n",
      "Train Epoch: 29 [640/2239 (29%)]\tLoss: 0.613914\n",
      "Train Epoch: 29 [960/2239 (43%)]\tLoss: 0.464218\n",
      "Train Epoch: 29 [1280/2239 (57%)]\tLoss: 0.537984\n",
      "Train Epoch: 29 [1600/2239 (71%)]\tLoss: 0.656242\n",
      "Train Epoch: 29 [1920/2239 (86%)]\tLoss: 0.469043\n",
      "Epoch 29 training time: 1588.02 seconds\n",
      "\n",
      "Test set: Average loss: 1.5307, Accuracy: 63/118 (53.39%)\n",
      "\n",
      "Train Epoch: 30 [0/2239 (0%)]\tLoss: 0.482406\n",
      "Train Epoch: 30 [320/2239 (14%)]\tLoss: 0.662479\n",
      "Train Epoch: 30 [640/2239 (29%)]\tLoss: 0.721902\n",
      "Train Epoch: 30 [960/2239 (43%)]\tLoss: 0.619160\n",
      "Train Epoch: 30 [1280/2239 (57%)]\tLoss: 0.451938\n",
      "Train Epoch: 30 [1600/2239 (71%)]\tLoss: 0.701615\n",
      "Train Epoch: 30 [1920/2239 (86%)]\tLoss: 1.021671\n",
      "Epoch 30 training time: 1599.52 seconds\n",
      "\n",
      "Test set: Average loss: 1.6503, Accuracy: 62/118 (52.54%)\n",
      "\n",
      "Train Epoch: 31 [0/2239 (0%)]\tLoss: 0.476084\n",
      "Train Epoch: 31 [320/2239 (14%)]\tLoss: 0.453865\n",
      "Train Epoch: 31 [640/2239 (29%)]\tLoss: 0.564040\n",
      "Train Epoch: 31 [960/2239 (43%)]\tLoss: 0.724360\n",
      "Train Epoch: 31 [1280/2239 (57%)]\tLoss: 0.816264\n",
      "Train Epoch: 31 [1600/2239 (71%)]\tLoss: 0.818589\n",
      "Train Epoch: 31 [1920/2239 (86%)]\tLoss: 0.437948\n",
      "Epoch 31 training time: 2037.80 seconds\n",
      "\n",
      "Test set: Average loss: 1.6561, Accuracy: 69/118 (58.47%)\n",
      "\n",
      "Epoch 00031: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Train Epoch: 32 [0/2239 (0%)]\tLoss: 0.743518\n",
      "Train Epoch: 32 [320/2239 (14%)]\tLoss: 0.488197\n",
      "Train Epoch: 32 [640/2239 (29%)]\tLoss: 0.329257\n",
      "Train Epoch: 32 [960/2239 (43%)]\tLoss: 0.505697\n",
      "Train Epoch: 32 [1280/2239 (57%)]\tLoss: 0.557757\n",
      "Train Epoch: 32 [1600/2239 (71%)]\tLoss: 0.523859\n",
      "Train Epoch: 32 [1920/2239 (86%)]\tLoss: 0.632869\n",
      "Epoch 32 training time: 2027.58 seconds\n",
      "\n",
      "Test set: Average loss: 1.6315, Accuracy: 65/118 (55.08%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchdiffeq\n",
    "import time\n",
    "\n",
    "# ResNet-50 model adapted for skin cancer prediction\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])  # Remove last FC layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# ODE function definition for the hidden state dynamics\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 2048)\n",
    "        )\n",
    "        self.apply(self._initialize_weights)  # Apply weight initialization\n",
    "\n",
    "    def _initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "\n",
    "# Combined model with ResNet and Neural ODE\n",
    "class ODEModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ODEModel, self).__init__()\n",
    "        self.resnet = ResNet50()\n",
    "        self.ode_func = ODEFunc()\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        t = torch.tensor([0., 1.]).to(x.device)\n",
    "        y = torchdiffeq.odeint(self.ode_func, x, t, method='dopri5')\n",
    "        return self.classifier(y[-1])\n",
    "\n",
    "# Function to compute loss\n",
    "def compute_loss(model, data, target):\n",
    "    output = model(data)\n",
    "    loss = nn.CrossEntropyLoss()(output, target)\n",
    "    return loss\n",
    "\n",
    "# Training routine\n",
    "def train(epoch, model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = compute_loss(model, data, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    end_time = time.time()\n",
    "    print(f'Epoch {epoch} training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Testing routine\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.CrossEntropyLoss(reduction='sum')(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.2f}%)\\n')\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# Load ISIC data with updated data augmentation\n",
    "def load_data(batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    train_dataset = ImageFolder('../data/Skin_cancer_ISIC/Train', transform=transform)\n",
    "    test_dataset = ImageFolder('../data/Skin_cancer_ISIC/Test', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return train_loader, test_loader, len(train_dataset.classes)\n",
    "\n",
    "# Main function to train and evaluate the model\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, test_loader, num_classes = load_data()\n",
    "    model = ODEModel(num_classes).to(device)\n",
    "    \n",
    "    # Using Adam with weight decay\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "    # Using ReduceLROnPlateau scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    for epoch in range(1, 51):\n",
    "        train(epoch, model, device, train_loader, optimizer)\n",
    "        test_loss, accuracy = test(model, device, test_loader)\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if epoch % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': test_loss,\n",
    "                'accuracy': accuracy\n",
    "            }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3433e-2b37-4768-9a9a-687c053a069a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
