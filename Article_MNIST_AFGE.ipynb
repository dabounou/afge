{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d441b7a-ab2c-49f2-924f-aef3737ddcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpro/opt/anaconda3/envs/Torch_Info_theory/lib/python3.9/site-packages/torchdiffeq/_impl/misc.py:15: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 0.1}\n",
      "  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training time: 141.12 seconds\n",
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 9845/10000 (98.45%)\n",
      "\n",
      "Epoch 2 training time: 147.06 seconds\n",
      "\n",
      "Test set: Average loss: 0.0364, Accuracy: 9884/10000 (98.84%)\n",
      "\n",
      "Epoch 3 training time: 146.55 seconds\n",
      "\n",
      "Test set: Average loss: 0.0341, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "Epoch 4 training time: 144.93 seconds\n",
      "\n",
      "Test set: Average loss: 0.0371, Accuracy: 9879/10000 (98.79%)\n",
      "\n",
      "Epoch 5 training time: 145.10 seconds\n",
      "\n",
      "Test set: Average loss: 0.0249, Accuracy: 9923/10000 (99.23%)\n",
      "\n",
      "Epoch 6 training time: 144.69 seconds\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      "Epoch 7 training time: 147.35 seconds\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 9920/10000 (99.20%)\n",
      "\n",
      "Epoch 8 training time: 147.58 seconds\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 9926/10000 (99.26%)\n",
      "\n",
      "Epoch 9 training time: 148.34 seconds\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 9944/10000 (99.44%)\n",
      "\n",
      "Epoch 10 training time: 152.50 seconds\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 9929/10000 (99.29%)\n",
      "\n",
      "Epoch 11 training time: 161.60 seconds\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Epoch 12 training time: 167.74 seconds\n",
      "\n",
      "Test set: Average loss: 0.0280, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "Epoch 13 training time: 177.52 seconds\n",
      "\n",
      "Test set: Average loss: 0.0286, Accuracy: 9915/10000 (99.15%)\n",
      "\n",
      "Epoch 14 training time: 182.26 seconds\n",
      "\n",
      "Test set: Average loss: 0.0260, Accuracy: 9919/10000 (99.19%)\n",
      "\n",
      "Epoch 15 training time: 179.15 seconds\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "Epoch 16 training time: 185.91 seconds\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 9941/10000 (99.41%)\n",
      "\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 17 training time: 183.01 seconds\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 9959/10000 (99.59%)\n",
      "\n",
      "Epoch 18 training time: 183.61 seconds\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 9957/10000 (99.57%)\n",
      "\n",
      "Epoch 19 training time: 192.48 seconds\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      "Epoch 20 training time: 186.61 seconds\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 9956/10000 (99.56%)\n",
      "\n",
      "Epoch 21 training time: 188.12 seconds\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      "Epoch 22 training time: 186.00 seconds\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 9954/10000 (99.54%)\n",
      "\n",
      "Epoch 23 training time: 190.20 seconds\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      "Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 24 training time: 192.14 seconds\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 9959/10000 (99.59%)\n",
      "\n",
      "Epoch 25 training time: 191.70 seconds\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      "Epoch 26 training time: 192.08 seconds\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 9961/10000 (99.61%)\n",
      "\n",
      "Epoch 27 training time: 189.35 seconds\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      "Epoch 28 training time: 187.40 seconds\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 9963/10000 (99.63%)\n",
      "\n",
      "Epoch 29 training time: 183.70 seconds\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 9962/10000 (99.62%)\n",
      "\n",
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 30 training time: 186.26 seconds\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 9963/10000 (99.63%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchdiffeq\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# Define a tagged module class\n",
    "class TaggedModule(nn.Module):\n",
    "    def __init__(self, tag):\n",
    "        super().__init__()\n",
    "        self.tag = tag\n",
    "\n",
    "# CNN for feature extraction\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
    "        self.dropout = nn.Dropout(0.5)  # Ajustez le taux de dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.batch_norm2(self.conv2(x)))\n",
    "        x = F.relu(self.batch_norm3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        return x\n",
    "\n",
    "# ODE Function for AFGE\n",
    "class ODEFunc(TaggedModule):\n",
    "    def __init__(self):\n",
    "        super().__init__(tag=\"ode\")\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        return self.net(y)\n",
    "\n",
    "# Augmented ODE Function with gradients for AFGE\n",
    "class AugmentedODEFunc(TaggedModule):\n",
    "    def __init__(self, func):\n",
    "        super().__init__(tag=\"ode\")\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, t, state):\n",
    "        y, adj_y = state[:, :128], state[:, 128:]\n",
    "        with torch.set_grad_enabled(True):\n",
    "            y.requires_grad_(True)\n",
    "            dy = self.func(t, y)\n",
    "            adj_dy = torch.autograd.grad(dy, y, adj_y, create_graph=True, retain_graph=True)[0]\n",
    "        return torch.cat([dy, adj_dy], dim=1)\n",
    "\n",
    "# Initializer network for dy(0)/dθ\n",
    "class InitializerNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the full model\n",
    "class ODEModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ODEModel, self).__init__()\n",
    "        self.cnn = CNN()\n",
    "        self.ode_func = ODEFunc()\n",
    "        self.aug_ode_func = AugmentedODEFunc(self.ode_func)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "        self.classifier.tag = \"non_ode\"\n",
    "        self.initializer = InitializerNetwork(128, 128)\n",
    "        self.last_adj_y = []  # Liste au lieu d'un seul tenseur\n",
    "\n",
    "    def forward(self, x, is_first_batch=False):\n",
    "        cnn_output = self.cnn(x)\n",
    "        batch_size = cnn_output.shape[0]\n",
    "\n",
    "        if self.training:\n",
    "            init_adj_y = self.initializer(cnn_output)\n",
    "\n",
    "            if is_first_batch or not self.last_adj_y:\n",
    "                adj_y = init_adj_y\n",
    "            else:\n",
    "                # Utiliser les dernières valeurs disponibles, répétées si nécessaire\n",
    "                last_adj_y = torch.cat(self.last_adj_y, dim=0)\n",
    "                last_adj_y = last_adj_y.repeat(batch_size // last_adj_y.shape[0] + 1, 1)[:batch_size]\n",
    "                adj_y = 0.5 * init_adj_y + 0.5 * last_adj_y.detach()\n",
    "\n",
    "            aug_state = torch.cat([cnn_output, adj_y], dim=1)\n",
    "            t = torch.tensor([0., 1.]).to(x.device)\n",
    "            aug_state = torchdiffeq.odeint(self.aug_ode_func, aug_state, t, method='dopri5', options={'step_size': 0.1})  # Ajustez les pas de temps\n",
    "            y1, adj_y1 = aug_state[-1, :, :128], aug_state[-1, :, 128:]\n",
    "\n",
    "            # Mettre à jour last_adj_y\n",
    "            self.last_adj_y = [adj_y1]\n",
    "\n",
    "            output = self.classifier(y1)\n",
    "            return output, y1, adj_y1\n",
    "        else:\n",
    "            t = torch.tensor([0., 1.]).to(x.device)\n",
    "            y1 = torchdiffeq.odeint(self.ode_func, cnn_output, t, method='dopri5', options={'step_size': 0.1})  # Ajustez les pas de temps\n",
    "            output = self.classifier(y1[-1])\n",
    "            return output\n",
    "\n",
    "# Function to get parameters based on tags\n",
    "def get_parameters_by_tag(model, tag):\n",
    "    for module in model.modules():\n",
    "        if hasattr(module, 'tag') and module.tag == tag:\n",
    "            yield from module.parameters()\n",
    "\n",
    "# Training function\n",
    "def train(epoch, model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    ode_params_before = copy.deepcopy(list(get_parameters_by_tag(model, \"ode\")))\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        is_first_batch = (batch_idx == 0)\n",
    "        output, y1, adj_y1 = model(data, is_first_batch)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Check if ODE parameters have changed\n",
    "    ode_params_after = list(get_parameters_by_tag(model, \"ode\"))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Epoch {epoch} training time: {end_time - start_time:.2f} seconds')\n",
    "\n",
    "# Testing function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.2f}%)\\n')\n",
    "    return test_loss, accuracy\n",
    "\n",
    "# Load data\n",
    "def load_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Main function to train and test the model\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, test_loader = load_data()\n",
    "    model = ODEModel().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)  # Ajustez le weight decay\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    for epoch in range(1, 31):\n",
    "        train(epoch, model, device, train_loader, optimizer)\n",
    "        test_loss, accuracy = test(model, device, test_loader)\n",
    "        scheduler.step(test_loss)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661ea44-0414-4d40-9a21-ec99d9cb7799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
